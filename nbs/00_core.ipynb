{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5fe9d72",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f690970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6e08f6",
   "metadata": {},
   "source": [
    "# skillhelper Design Specification\n",
    "\n",
    "## Goal\n",
    "\n",
    "Build `skillhelper` â€” a Python package that enables solveit to discover, load, and use Agent Skills (Anthropic's open standard for giving agents capabilities). Skills should also work with Claude Code via filesystem compatibility.\n",
    "\n",
    "## Agent Skills Standard\n",
    "\n",
    "Skills are directories with a spec-compliant structure:\n",
    "```\n",
    "skill-name/\n",
    "â”œâ”€â”€ SKILL.md          # Required: YAML frontmatter + markdown instructions\n",
    "â”œâ”€â”€ scripts/          # Optional: executable code\n",
    "â”œâ”€â”€ references/       # Optional: additional documentation  \n",
    "â””â”€â”€ assets/           # Optional: templates, resources\n",
    "```\n",
    "\n",
    "SKILL.md frontmatter (required fields):\n",
    "- `name`: kebab-case, 1-64 chars, must match directory name\n",
    "- `description`: what it does and when to use it, max 1024 chars\n",
    "\n",
    "Optional fields: `license`, `compatibility`, `metadata`, `allowed-tools`\n",
    "\n",
    "**Progressive disclosure**: Agents load only metadata at startup, full instructions on activation, resources on demand.\n",
    "\n",
    "## skillhelper Architecture\n",
    "\n",
    "### Discovery (multiple sources)\n",
    "1. **Entry points** â€” pip-installed skill packages register via `[project.entry-points.\"skillhelper.skills\"]`\n",
    "2. **Filesystem** â€” `~/.skills/` (user), `./skills/` (project-local)\n",
    "3. **Environment** â€” `SOLVEIT_SKILLS_PATH` for custom paths\n",
    "\n",
    "### Core Abstractions\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class Skill:\n",
    "    name: str\n",
    "    description: str\n",
    "    path: Path\n",
    "    instructions: str  # Full SKILL.md body\n",
    "    compatibility: Optional[str]\n",
    "    allowed_tools: Optional[str]\n",
    "    metadata: Optional[dict]\n",
    "    \n",
    "    def load_reference(self, name: str) -> str: ...\n",
    "    def run_script(self, name: str, *args) -> str: ...\n",
    "    def asset_path(self, name: str) -> Path: ...\n",
    "```\n",
    "\n",
    "### Tools for solveit AI (exposed via `&` syntax)\n",
    "- `discover_skills(paths)` â€” scan and register skills\n",
    "- `list_skills()` â€” show available skills with descriptions\n",
    "- `activate_skill(name)` â€” load full instructions into context\n",
    "- `skill_reference(skill_name, ref_name)` â€” load reference docs\n",
    "- `skill_asset_path(skill_name, asset_name)` â€” get asset path\n",
    "- `skill_tool_info()` â€” returns `<available_skills>` XML for prompt injection\n",
    "\n",
    "### Claude Code Compatibility\n",
    "- `skillhelper sync` command creates symlinks from `~/.skills/` to pip-installed skill locations\n",
    "- Optional meta-skill teaches Claude Code how to discover skillhelper-managed skills\n",
    "- Same skill format works in both environments\n",
    "\n",
    "## Skill Package Structure (for pip-installable skills)\n",
    "\n",
    "```\n",
    "my-skill/\n",
    "â”œâ”€â”€ pyproject.toml\n",
    "â””â”€â”€ src/\n",
    "    â””â”€â”€ my_skill/\n",
    "        â”œâ”€â”€ __init__.py      # get_skill_path() â†’ Path to skill/\n",
    "        â””â”€â”€ skill/           # Spec-compliant skill directory\n",
    "            â”œâ”€â”€ SKILL.md\n",
    "            â”œâ”€â”€ scripts/\n",
    "            â””â”€â”€ references/\n",
    "```\n",
    "\n",
    "pyproject.toml entry point:\n",
    "```toml\n",
    "[project.entry-points.\"skillhelper.skills\"]\n",
    "my-skill = \"my_skill:get_skill_path\"\n",
    "```\n",
    "\n",
    "## Development with nbdev\n",
    "\n",
    "- Skill instructions authored in notebooks, exported to SKILL.md\n",
    "- Code cells export to scripts/ or Python modules\n",
    "- Tests verify skill functionality\n",
    "- Package includes entry points for skillhelper discovery\n",
    "\n",
    "## Key References\n",
    "\n",
    "- Agent Skills spec: https://agentskills.io/specification\n",
    "- Reference implementation: `skills-ref/` in current directory (parser, validator, models)\n",
    "- dialoghelper patterns: https://answerdotai.github.io/dialoghelper/core.html.md\n",
    "- Example skills: `../skills/custom_skills/`\n",
    "\n",
    "## Template Pattern\n",
    "\n",
    "Follow `dialoghelper` patterns:\n",
    "- Functions with type annotations + docstrings become tools\n",
    "- `find_dname()` pattern for context discovery\n",
    "- `call_endp()` for API communication where needed\n",
    "- Entry in tool info function for solveit integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c7a81f",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Agent Skills Homepage](https://agentskills.io/home)\n",
    "- [Agent Skill Specification](https://agentskills.io/specification)\n",
    "- [Whhat are Skills](https://agentskills.io/what-are-skills)\n",
    "- [Integrate Skills](https://agentskills.io/integrate-skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c38bddd",
   "metadata": {},
   "source": [
    "Greetings! I'm Chuck and I want to build skillhelper using the fast.ai/answer.ai/solveit approach of literate and exploratory programming. I'm ok with you writeing the code, but it should be in small chunks and use the https://docs.fast.ai/dev/style.html style guide that you should look up if you are not familiar with how to code in this style. Don't write any code just yet, but think through what we want to do here.\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ \n",
    "\n",
    "Greetings Chuck! Great to work with you on skillhelper.\n",
    "\n",
    "Let me first check the fast.ai style guide to ensure I'm aligned with the coding conventions:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01DNo6Uk4Ug1UuETFGv2bbGK\",\n",
    "  \"call\": {\n",
    "    \"function\": \"read_url\",\n",
    "    \"arguments\": {\n",
    "      \"url\": \"https://docs.fast.ai/dev/style.html\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'[ fastai ](../index.html)\\\\n\\\\n  * [ __ ](https://github.com/fastai/fastai)\\\\n\\\\n\\\\n\\\\n[ __ ]( \\\"Toggle reader mode\\\")\\\\n\\\\n__\\\\n\\\\n  1. [fastai Development](../dev-setup.html)\\\\n  2. [fastai coding style](../dev/style.html)\\\\n\\\\n\\\\n\\\\n  * [ Welcome to fastai](../index.html)\\\\n\\\\n  * [ Quick start](../quick_start.html)\\\\n\\\\n  * Tutorials __\\\\n\\\\n    * [ Tutorials](../tutorial.html)\\\\n\\\\n    * Beginner __\\\\n\\\\n      * [ Computer vision intro](../tutorial.vision.html)\\\\n\\\\n      * [ Text transfer learning](../tutorial.text.html)\\\\n\\\\n      * [ Tabular training](../tutorial.tabular.html)\\\\n\\\\n      * [ Collaborative filtering t<TRUNCATED>\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Good, I've reviewed the fast.ai style guide. Now let me think through what we want to accomplish with skillhelper.\n",
    "\n",
    "**Key design goals based on the spec:**\n",
    "\n",
    "1. **Progressive disclosure** â€” Load only metadata at startup, full instructions on activation, resources on demand\n",
    "2. **Multiple discovery sources** â€” Entry points, filesystem (`~/.skills/`, `./skills/`), and env vars\n",
    "3. **Claude Code compatibility** â€” Skills should work in both solveit and Claude Code\n",
    "\n",
    "**Proposed development order (small steps):**\n",
    "\n",
    "1. **Parse SKILL.md** â€” Start with the core: a function to read and parse YAML frontmatter + markdown body from a single SKILL.md file\n",
    "2. **Skill dataclass** â€” Simple dataclass holding parsed data + path\n",
    "3. **Discover from filesystem** â€” Scan directories for valid skills\n",
    "4. **Entry point discovery** â€” Load skills registered via pip packages\n",
    "5. **Tool functions** â€” `list_skills()`, `activate_skill()`, etc. for solveit integration\n",
    "6. **CLI sync command** â€” For Claude Code compatibility\n",
    "\n",
    "**Questions for you before we start coding:**\n",
    "\n",
    "1. Should we look at the reference implementation in `skills-ref/` first to see how they handle SKILL.md parsing, or start fresh?\n",
    "2. Do you want to begin with the SKILL.md parser, or would you prefer to start with the `Skill` dataclass structure?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146393ae",
   "metadata": {},
   "source": [
    "Ok. I have added the agentskills repository as a git submodule. the skills-ref is in the submodule directory.\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Let's take a look at what's in the skills-ref directory to understand the reference implementation:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01TBYXEsVjYigZsB4qZJpSpQ\",\n",
    "  \"call\": {\n",
    "    \"function\": \"view\",\n",
    "    \"arguments\": {\n",
    "      \"path\": \"skills-ref\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'Error: File not found: /app/data/research/skillhelper/nbs/skills-ref'\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Let me check the current directory structure to find where the submodule is located:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01RZ2VZ86rj9wShFwuPTmp6s\",\n",
    "  \"call\": {\n",
    "    \"function\": \"view\",\n",
    "    \"arguments\": {\n",
    "      \"path\": \".\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'Directory contents of /app/data/research/skillhelper/nbs:\\\\n/app/data/research/skillhelper/nbs/styles.css\\\\n/app/data/research/skillhelper/nbs/_quarto.yml\\\\n/app/data/research/skillhelper/nbs/00_core.ipynb\\\\n/app/data/research/skillhelper/nbs/index.ipynb\\\\n/app/data/research/skillhelper/nbs/nbdev.yml'\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Let me check the parent directory:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_014YdpeDJXAekFZofnP6QdzJ\",\n",
    "  \"call\": {\n",
    "    \"function\": \"view\",\n",
    "    \"arguments\": {\n",
    "      \"path\": \"..\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'Directory contents of /app/<TRUNCATED>\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Great! Found it at `../agentskills/skills-ref`. Let me look at the key files in the reference implementation:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_0181aqimKGrW62ij553mrYNd\",\n",
    "  \"call\": {\n",
    "    \"function\": \"view\",\n",
    "    \"arguments\": {\n",
    "      \"path\": \"../agentskills/skills-ref/src/skills_ref\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'Directory contents of /app/<TRUNCATED>\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Perfect! The reference implementation has exactly what we need. The key files are:\n",
    "- `models.py` - Data structures for skills\n",
    "- `parser.py` - SKILL.md parsing logic\n",
    "- `validator.py` - Validation rules\n",
    "- `prompt.py` - For generating prompts (progressive disclosure)\n",
    "\n",
    "Should I look at these files to understand their approach, or would you prefer to start fresh with our own implementation following fast.ai style?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59c33c6",
   "metadata": {},
   "source": [
    "I'm fine using these as reference, but we should re-implement them using the fast.ai style and fastcore.\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! Let's start by looking at their models to understand the data structures, then we'll reimplement using fast.ai style and fastcore:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01Eg3WFbN9wGReuQJbs1PnfS\",\n",
    "  \"call\": {\n",
    "    \"function\": \"view\",\n",
    "    \"arguments\": {\n",
    "      \"path\": \"../agentskills/skills-ref/src/skills_ref/models.py\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'\\\"\\\"\\\"Data models for Agent Skills.\\\"\\\"\\\"\\\\n\\\\nfrom dataclasses import dataclass, field\\\\nfrom typing import Optional\\\\n\\\\n\\\\n@dataclass\\\\nclass SkillProperties:\\\\n    \\\"\\\"\\\"Properties parsed from a skill\\\\'s SKILL.md frontmatter.\\\\n\\\\n    Attributes:\\\\n        name: Skill name in kebab-case (required)\\\\n        description: What the skill does and when the model should use it (required)\\\\n        license: License for the skill (optional)\\\\n        compatibility: Compatibility information for the skill (optional)\\\\n        allowed_tools: Tool patterns the skill requires (optional, experimental)\\\\n        metadata: Key<TRUNCATED>\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Now let's look at the parser to see how they extract YAML frontmatter:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01J1Y6Wi1mHRSXqk3ZxUEZE6\",\n",
    "  \"call\": {\n",
    "    \"function\": \"view\",\n",
    "    \"arguments\": {\n",
    "      \"path\": \"../agentskills/skills-ref/src/skills_ref/parser.py\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'\\\"\\\"\\\"YAML frontmatter parsing for SKILL.md files.\\\"\\\"\\\"\\\\n\\\\nfrom pathlib import Path\\\\nfrom typing import Optional\\\\n\\\\nimport strictyaml\\\\n\\\\nfrom .errors import ParseError, ValidationError\\\\nfrom .models import SkillProperties\\\\n\\\\n\\\\ndef find_skill_md(skill_dir: Path) -> Optional[Path]:\\\\n    \\\"\\\"\\\"Find the SKILL.md file in a skill directory.\\\\n\\\\n    Prefers SKILL.md (uppercase) but accepts skill.md (lowercase).\\\\n\\\\n    Args:\\\\n        skill_dir: Path to the skill directory\\\\n\\\\n    Returns:\\\\n        Path to the SKILL.md file, or None if not found\\\\n    \\\"\\\"\\\"\\\\n    for name in (\\\"SKILL.md\\\", \\\"skill.md\\\"):\\\\n        path <TRUNCATED>\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Good! Now I understand their approach. They use `strictyaml` for parsing. \n",
    "\n",
    "**Key observations:**\n",
    "1. They split models (SkillProperties) from the full Skill concept\n",
    "2. They use simple string splitting for frontmatter extraction\n",
    "3. They have separate parsing and validation steps\n",
    "\n",
    "**For our fast.ai style implementation, should we:**\n",
    "1. Start with a simple frontmatter parser function (using fastcore utilities where applicable)?\n",
    "2. Or begin with the `Skill` dataclass that will hold everything we need?\n",
    "\n",
    "Which would you like to tackle first?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9d4ddc",
   "metadata": {},
   "source": [
    "So. We want to test this as we go using the fast.ai approach. We is there an example skill we should create in the repository?\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good thinking! Having a test skill will help us develop incrementally. Let me check if there are example skills in the agentskills repo:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_017xABFEix13bBxYRg77cMTQ\",\n",
    "  \"call\": {\n",
    "    \"function\": \"rg\",\n",
    "    \"arguments\": {\n",
    "      \"argstr\": \"-l SKILL.md ../agentskills\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'../a<TRUNCATED>\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Let me look for actual example skills in their test fixtures:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_011XrEv3k6sjMGhLtLSuu3BJ\",\n",
    "  \"call\": {\n",
    "    \"function\": \"view\",\n",
    "    \"arguments\": {\n",
    "      \"path\": \"../agentskills/skills-ref/tests\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'Directory contents of /app/data/research/skillhelper/agentskills/skills-ref/tests:\\\\n/app/data/research/skillhelper/agentskills/skills-ref/tests/test_prompt.py\\\\n/app/data/research/skillhelper/agentskills/skills-ref/tests/__init__.py\\\\n/app/data/research/skillhelper/agentskills/skills-ref/tests/test_parser.py\\\\n/app/data/research/skillhelper/agentskills/skills-ref/tests/test_validator.py'\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01Kzzd4BFfZ3HFotwi1pnNfm\",\n",
    "  \"call\": {\n",
    "    \"function\": \"rg\",\n",
    "    \"arguments\": {\n",
    "      \"argstr\": \"-A 10 fixtures ../agentskills/skills-ref/tests/test_parser.py\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"''\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01WK6wgipbFwk2kjVzsQBE7B\",\n",
    "  \"call\": {\n",
    "    \"function\": \"view\",\n",
    "    \"arguments\": {\n",
    "      \"path\": \"../agentskills/skills-ref/tests/test_parser.py\",\n",
    "      \"view_range\": \"[1, 50]\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'\\\"\\\"\\\"Tests for parser module.\\\"\\\"\\\"\\\\n\\\\nimport pytest\\\\n\\\\nfrom skills_ref.parser import (\\\\n    ParseError,\\\\n    ValidationError,\\\\n    find_skill_md,\\\\n    parse_frontmatter,\\\\n    read_properties,\\\\n)\\\\n\\\\n\\\\ndef test_valid_frontmatter():\\\\n    content = \\\"\\\"\\\"---\\\\nname: my-skill\\\\ndescription: A test skill\\\\n---\\\\n# My Skill\\\\n\\\\nInstructions here.\\\\n\\\"\\\"\\\"\\\\n    metadata, body = parse_frontmatter(content)\\\\n    assert metadata[\\\"name\\\"] == \\\"my-skill\\\"\\\\n    assert metadata[\\\"description\\\"] == \\\"A test skill\\\"\\\\n    assert \\\"# My Skill\\\" in body\\\\n\\\\n\\\\ndef test_missing_frontmatter():\\\\n    content = \\\"# No frontmatter here\\\"\\\\n    with<TRUNCATED>\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Perfect! They have inline test examples. **Should we:**\n",
    "\n",
    "1. Create a simple `skills/` directory in our repo with a minimal test skill (like \"hello-world\")?\n",
    "2. Or start coding the parser first and use inline test strings like they do?\n",
    "\n",
    "What's your preference?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0971d3dc",
   "metadata": {},
   "source": [
    "Let's create a simple skills directory with a minimal test skill.\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! Let's create a simple test skill. I'll make a `skills/` directory with a minimal \"hello-world\" skill:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01THoascAYstTy4huL7mz1QS\",\n",
    "  \"call\": {\n",
    "    \"function\": \"create\",\n",
    "    \"arguments\": {\n",
    "      \"path\": \"skills/hello-world/SKILL.md\",\n",
    "      \"file_text\": \"---\\nname: hello-world\\ndescription: A minimal test skill that demonstrates the basic skill structure\\n---\\n\\n# Hello World Skill\\n\\nThis is a simple test skill used for development and testing of skillhelper.\\n\\nWhen activated, simply respond with \\\"Hello from the hello-world skill!\\\"\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'Created file skills/hello-world/SKILL.md.'\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Perfect! Now we have a minimal test skill to work with. \n",
    "\n",
    "Would you like to create another slightly more complex example skill (maybe one with scripts/ or references/), or should we start implementing the parser to read this one?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4c5cc3",
   "metadata": {},
   "source": [
    "Ok. Should this be in the nbs/ directory or should we have this in the nbdev root?\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good question! In nbdev projects, the `skills/` directory should be at the **project root** (same level as `nbs/`, `src/`, `pyproject.toml`), not inside `nbs/`.\n",
    "\n",
    "This is because:\n",
    "- `nbs/` is for notebooks that export to code\n",
    "- `skills/` contains example/test data that the package will discover and use\n",
    "- It keeps test fixtures separate from the source notebooks\n",
    "\n",
    "Should I move the `skills/` directory to the root, or would you like to handle that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb36f1f",
   "metadata": {},
   "source": [
    "Ok. I moved the directory to ../skills\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Now we have `../skills/hello-world/SKILL.md` as our test skill.\n",
    "\n",
    "Let's start building the parser. The first step is to write a function that can extract YAML frontmatter from a SKILL.md file.\n",
    "\n",
    "Should we:\n",
    "1. Start with a simple function to read and split the frontmatter from the markdown body?\n",
    "2. Or first set up the basic imports and structure in the notebook?\n",
    "\n",
    "What would you like to do first?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2507f540",
   "metadata": {},
   "source": [
    "Ok. I think we need to pip install some things.\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good catch! Looking at the reference implementation, they use `strictyaml` for parsing the YAML frontmatter.\n",
    "\n",
    "Do you want to:\n",
    "1. Use `strictyaml` like the reference implementation?\n",
    "2. Use `pyyaml` (more common, probably already available)?\n",
    "3. Use something else?\n",
    "\n",
    "What's your preference?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3d1001",
   "metadata": {},
   "source": [
    "What is the difference?\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good question! Here are the key differences:\n",
    "\n",
    "**`pyyaml`** (standard library choice):\n",
    "- Most widely used Python YAML library\n",
    "- Permissive - accepts various YAML formats\n",
    "- Less validation by default\n",
    "- Likely already installed in many environments\n",
    "\n",
    "**`strictyaml`** (what the reference uses):\n",
    "- Enforces stricter YAML subset (no complex types, dates, etc.)\n",
    "- Better error messages\n",
    "- More predictable parsing (all values are strings initially)\n",
    "- Designed to avoid YAML's \"gotchas\"\n",
    "\n",
    "For a spec-compliant implementation where we want predictable parsing of simple key-value frontmatter, `strictyaml` makes sense. But `pyyaml` would work fine too if we add our own validation.\n",
    "\n",
    "Which approach appeals to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6aee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import *\n",
    "import strictyaml\n",
    "from fastcore.xtras import *\n",
    "from fastcore.basics import first\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "from fastcore.basics import patch\n",
    "from safecmd import safe_run\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018dfb29",
   "metadata": {},
   "source": [
    "Ok. strictyaml is installed and the cell is marked for export. Are there other libraries we need to import at this point?\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ \n",
    "\n",
    "For parsing SKILL.md files, we'll need `Path` from pathlib. Beyond that, we can add imports as we need them.\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "```\n",
    "\n",
    "That should be enough to get started with the frontmatter parser. Ready to write the first function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f4b9e5",
   "metadata": {},
   "source": [
    "I think fastcore also has some path utilities?\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes, great observation! `fastcore.xtras` has `Path` extensions. Since you're already importing from `fastcore`, you likely have access to enhanced `Path` functionality.\n",
    "\n",
    "Let me check what path utilities are available in fastcore that might be useful:\n",
    "\n",
    "```python\n",
    "from fastcore.xtras import *\n",
    "```\n",
    "\n",
    "This gives you things like `Path.ls()`, `Path.readlines()`, and other convenient methods. Would you like to add this import, or explore what's available first?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65145e1a",
   "metadata": {},
   "source": [
    "I've added the import. This is a link to the documentation https://fastcore.fast.ai/xtras.html.md.\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Let me check the documentation to see what's available:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01LXAZYE7VKHxgPThTcD2VrN\",\n",
    "  \"call\": {\n",
    "    \"function\": \"read_url\",\n",
    "    \"arguments\": {\n",
    "      \"url\": \"https://fastcore.fast.ai/xtras.html.md\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'<html><body># Utility functions\\\\n\\\\n\\\\n<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->\\\\n\\\\n## File Functions\\\\n\\\\nUtilities (other than extensions to Pathlib.Path) for dealing with IO.\\\\n\\\\n------------------------------------------------------------------------\\\\n\\\\n<a href=\\\"https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/xtras.py#L35\\\" style=\\\"float:right; font-size:smaller\\\" target=\\\"_blank\\\">source</a>\\\\n\\\\n### walk\\\\n\\\\n&gt;  walk (path:pathlib.Path|str, symlinks:bool=True, keep_file:<built->            infunctioncallable&gt;=<function ret_true=\\\"\\\">, keep_folder:<built->            i<TRUNCATED>\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Great! Now I can see the useful Path utilities. For our SKILL.md parser, we'll want:\n",
    "\n",
    "- `Path.read_text()` (standard pathlib) to read the file\n",
    "- Potentially `Path.ls()` for directory discovery later\n",
    "\n",
    "Now we're ready to start writing the frontmatter parser. Should we begin with a simple function that:\n",
    "1. Reads a SKILL.md file\n",
    "2. Splits the YAML frontmatter from the markdown body\n",
    "\n",
    "What do you think?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1442b1ff",
   "metadata": {},
   "source": [
    "Yes. I like this approach. Go ahead.\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! Let's write a simple function to parse the frontmatter. Here's the first piece:\n",
    "\n",
    "```python\n",
    "def parse_frontmatter(content:str):\n",
    "    \"Split YAML frontmatter and markdown body from SKILL.md content\"\n",
    "    if not content.startswith('---\\n'):\n",
    "        raise ValueError(\"SKILL.md must start with YAML frontmatter (---)\")\n",
    "    \n",
    "    parts = content.split('---\\n', 2)\n",
    "    if len(parts) < 3:\n",
    "        raise ValueError(\"SKILL.md frontmatter must be closed with ---\")\n",
    "    \n",
    "    yaml_str = parts[1]\n",
    "    body = parts[2].strip()\n",
    "    \n",
    "    metadata = strictyaml.load(yaml_str).data\n",
    "    return metadata, body\n",
    "```\n",
    "\n",
    "This splits on `---` delimiters and uses `strictyaml` to parse the YAML section. Would you like to test this with our hello-world skill?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_frontmatter(content:str):\n",
    "    \"Split YAML frontmatter and markdown body from SKILL.md content\"\n",
    "    if not content.startswith('---\\n'):\n",
    "        raise ValueError(\"SKILL.md must start with YAML frontmatter (---)\")\n",
    "    \n",
    "    parts = content.split('---\\n', 2)\n",
    "    if len(parts) < 3:\n",
    "        raise ValueError(\"SKILL.md frontmatter must be closed with ---\")\n",
    "    \n",
    "    yaml_str = parts[1]\n",
    "    body = parts[2].strip()\n",
    "    \n",
    "    try:\n",
    "        metadata = strictyaml.load(yaml_str).data\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Invalid YAML frontmatter: {e}\\nHint: Use block-style YAML (no flow-style arrays like [a,b,c])\")\n",
    "    \n",
    "    return metadata, body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9357d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_path = Path('../skills/hello-world/SKILL.md')\n",
    "content = skill_path.read_text()\n",
    "metadata, body = parse_frontmatter(content)\n",
    "print(metadata)\n",
    "print('\\n---\\n')\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38922652",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert metadata['name'] == 'hello-world'\n",
    "assert 'description' in metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ea11c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class Skill:\n",
    "    \"An Agent Skill loaded from a SKILL.md file\"\n",
    "    name: str\n",
    "    description: str\n",
    "    path: Path\n",
    "    instructions: str\n",
    "    license: Optional[str] = None\n",
    "    compatibility: Optional[str] = None\n",
    "    allowed_tools: Optional[str] = None\n",
    "    metadata: Optional[dict] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7695a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_skill(skill_dir:Path):\n",
    "    \"Load a skill from a directory containing SKILL.md\"\n",
    "    skill_md = first(skill_dir/nm for nm in ('SKILL.md', 'skill.md') if (skill_dir/nm).exists())\n",
    "    if not skill_md: raise FileNotFoundError(f\"No SKILL.md found in {skill_dir}\")\n",
    "    \n",
    "    content = skill_md.read_text()\n",
    "    md, body = parse_frontmatter(content)\n",
    "    \n",
    "    return Skill(\n",
    "        name=md['name'], \n",
    "        description=md['description'],\n",
    "        path=skill_dir, \n",
    "        instructions=body,\n",
    "        license=md.get('license'),\n",
    "        compatibility=md.get('compatibility'),\n",
    "        allowed_tools=md.get('allowed-tools'),  # Fix: use hyphen\n",
    "        metadata=md.get('metadata')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5207e752",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill = load_skill(Path('../skills/hello-world'))\n",
    "assert skill.name == 'hello-world'\n",
    "assert skill.path == Path('../skills/hello-world')\n",
    "print(skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66053bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill2 = load_skill(Path('../skills/code-reviewer'))\n",
    "assert skill2.name == 'code-reviewer'\n",
    "assert skill2.license == 'MIT'\n",
    "assert skill2.metadata is not None\n",
    "print(skill2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20807d3e",
   "metadata": {},
   "source": [
    "## Skill Discovery\n",
    "\n",
    "We'll implement multiple discovery sources:\n",
    "1. Filesystem paths (current focus)\n",
    "2. Entry points from pip packages (later)\n",
    "3. Environment variables (later)\n",
    "\n",
    "Starting with filesystem discovery to support our development workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c74f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def discover_skills(skill_path:Path):\n",
    "    \"Find all skills in a directory by looking for SKILL.md files\"\n",
    "    skill_path = Path(skill_path)\n",
    "    skills = []\n",
    "    for skill_dir in skill_path.iterdir():\n",
    "        if not skill_dir.is_dir(): continue\n",
    "        if not any((skill_dir/nm).exists() for nm in ('SKILL.md', 'skill.md')): continue\n",
    "        skills.append(load_skill(skill_dir))\n",
    "    return skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b05b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_skills = discover_skills(Path('../skills'))\n",
    "assert len(all_skills) == 2\n",
    "for s in all_skills:\n",
    "    print(f\"{s.name}: {s.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da699023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def load_reference(self:Skill, name:str):\n",
    "    \"Load a reference document from the references/ directory\"\n",
    "    ref_path = self.path/'references'/name\n",
    "    if not ref_path.exists(): raise FileNotFoundError(f\"Reference '{name}' not found in {self.path}\")\n",
    "    return ref_path.read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6304823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_content = skill2.load_reference('checklist.md')\n",
    "assert '# Code Review Checklist' in ref_content\n",
    "print(ref_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a4024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def asset_path(self:Skill, name:str):\n",
    "    \"Get path to an asset file in the assets/ directory\"\n",
    "    asset = self.path/'assets'/name\n",
    "    if not asset.exists(): raise FileNotFoundError(f\"Asset '{name}' not found in {self.path}\")\n",
    "    return asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c09be",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_path = skill2.asset_path('review-template.md')\n",
    "assert template_path.exists()\n",
    "print(template_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33177d4",
   "metadata": {},
   "source": [
    "Ok. I want to think through the run_cmd a bit before we implement it. Could you read the safecmd docs: https://answerdotai.github.io/safecmd/index.html.md and https://answerdotai.github.io/safecmd/bashxtract.html.md\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_017Kvz9m3hRWdTkX2RpcSkPq\",\n",
    "  \"call\": {\n",
    "    \"function\": \"read_url\",\n",
    "    \"arguments\": {\n",
    "      \"url\": \"https://answerdotai.github.io/safecmd/index.html.md\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'<html><body># safecmd\\\\n\\\\n\\\\n<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->\\\\n\\\\n## Introduction\\\\n\\\\nRunning shell commands from untrusted sources\\u2014like LLM-generated code,\\\\nuser input, or third-party scripts\\u2014is risky. A command that looks\\\\ninnocent might contain hidden redirects, command substitutions, or\\\\ndangerous flags that could modify or delete files, exfiltrate data, or\\\\nworse.\\\\n\\\\n**safecmd** solves this by validating bash commands against an allowlist\\\\nbefore execution. Instead of trying to blacklist dangerous patterns\\\\n(which is error-prone and easy to bypass), safecmd uses a <TRUNCATED>\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_014oRi59Bhp1CHwxKpYYv5PT\",\n",
    "  \"call\": {\n",
    "    \"function\": \"read_url\",\n",
    "    \"arguments\": {\n",
    "      \"url\": \"https://answerdotai.github.io/safecmd/bashxtract.html.md\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'<html><body># Bashxtract API\\\\n\\\\n\\\\n<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->\\\\n\\\\n## Introduction\\\\n\\\\n`safecmd.bashxtract` provides tools for parsing and extracting commands\\\\nfrom bash command strings. It\\u2019s designed for security-conscious\\\\napplications where you need to understand exactly what commands a shell\\\\nscript will execute before running it.\\\\n\\\\nThe core use case is validating shell commands from untrusted sources\\\\n(like LLM-generated commands) against an allowlist. Rather than trying\\\\nto regex-match bash syntax\\u2014which is notoriously tricky\\u2014this module uses\\\\n`shfmt`, a pro<TRUNCATED>\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Perfect! Now I understand `safecmd`. Here's what I'm thinking for `run_script()`:\n",
    "\n",
    "**Key considerations:**\n",
    "1. Scripts in `scripts/` directory could be Python, bash, or other executables\n",
    "2. We need to safely execute them without allowing arbitrary command injection\n",
    "3. `safe_run()` is perfect for bash scripts but we also need to handle Python scripts\n",
    "\n",
    "**Approach:**\n",
    "- For Python scripts: Use `subprocess.run()` with the Python interpreter\n",
    "- For bash/shell scripts: Use `safe_run()` with appropriate allowlist\n",
    "- Detect script type by extension or shebang\n",
    "\n",
    "What do you think about this approach? Should we support both Python and bash scripts, or start simpler with just one type?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b9f5e8",
   "metadata": {},
   "source": [
    "So, I think we want to use https://fastcore.fast.ai/tools.html.md run_cmd.\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ \n",
    "\n",
    "\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01MiWKv8VqrWr3mUsaQLgT5c\",\n",
    "  \"call\": {\n",
    "    \"function\": \"read_url\",\n",
    "    \"arguments\": {\n",
    "      \"url\": \"https://fastcore.fast.ai/tools.html.md\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'<html><body># LLM tools\\\\n\\\\n\\\\n<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->\\\\n\\\\n## Bash Tools\\\\n\\\\n------------------------------------------------------------------------\\\\n\\\\n<a href=\\\"https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/tools.py#L14\\\" style=\\\"float:right; font-size:smaller\\\" target=\\\"_blank\\\">source</a>\\\\n\\\\n### run_cmd\\\\n\\\\n&gt;  run_cmd (cmd:str, argstr:str=\\\\'\\\\', disallow_re:str=None, allow_re:str=None)\\\\n\\\\n*Run `cmd` passing split `argstr`, optionally checking for allowed\\\\nargstr*\\\\n\\\\n<table>\\\\n<colgroup>\\\\n<col style=\\\"width: 6%\\\"/>\\\\n<col style=\\\"width: 25%\\\"/>\\\\n<col style<TRUNCATED>\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Good! `run_cmd` from fastcore is simpler and safer - it doesn't go through the shell, so wildcards and command substitution won't work (which is a security feature). It also returns errors as strings rather than raising exceptions, which is LLM-friendly.\n",
    "\n",
    "For `run_script()`, should we:\n",
    "1. Use `run_cmd` with `python` as the command for `.py` scripts?\n",
    "2. Support other script types (bash, etc.) based on extension or shebang?\n",
    "\n",
    "What's your preference?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68db4fcc",
   "metadata": {},
   "source": [
    "How do we combine run_cmd with safe_run?\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good question! Let's think about this:\n",
    "\n",
    "- `run_cmd` (fastcore) - Runs a command with args, doesn't use shell, safer by default\n",
    "- `safe_run` (safecmd) - Validates bash commands against allowlist before running\n",
    "\n",
    "They serve different purposes:\n",
    "- `run_cmd` is for running specific executables (like `python script.py`)\n",
    "- `safe_run` is for validating full bash command strings before execution\n",
    "\n",
    "For `run_script()`, we probably want `run_cmd` since we're executing known scripts from the `scripts/` directory, not arbitrary bash commands. The script path itself is trusted (it's in the skill directory), we just need to pass user arguments safely.\n",
    "\n",
    "Does that make sense, or were you thinking of a different use case where we'd need both?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e90d1d1",
   "metadata": {},
   "source": [
    "How might we make a safe/verifiable skill that verifies the skill before executing it?\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ \n",
    "\n",
    "Interesting question! A few approaches come to mind:\n",
    "\n",
    "1. **Use `allowed-tools` field** â€” Skills already declare what tools they need in frontmatter. We could parse scripts and verify they only use declared tools.\n",
    "\n",
    "2. **Script hashing** â€” Compute hash when skill is installed, verify before execution.\n",
    "\n",
    "3. **Static analysis** â€” Use `bashxtract` to extract commands from bash scripts (or `ast` for Python) and validate against an allowlist.\n",
    "\n",
    "4. **Combine `safe_run` + `allowed-tools`** â€” Build the allowlist dynamically from the skill's declared `allowed-tools` field.\n",
    "\n",
    "Option 4 seems elegant - the skill author declares what tools the skill needs, and `safe_run` enforces that at runtime.\n",
    "\n",
    "Which direction interests you?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9875e134",
   "metadata": {},
   "source": [
    "So, I like a all of these options, maybe as a form of progressive safety.\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ \n",
    "\n",
    "I like that idea! Progressive safety could look like:\n",
    "\n",
    "**Level 1 - Declaration** \n",
    "Skill declares `allowed-tools` in frontmatter. Quick check: \"does this skill declare what it needs?\"\n",
    "\n",
    "**Level 2 - Static verification**\n",
    "Before first run, analyze scripts with `bashxtract` (bash) or `ast` (Python) to verify they only use declared tools.\n",
    "\n",
    "**Level 3 - Runtime enforcement**\n",
    "Use `safe_run` with allowlist built dynamically from `allowed-tools`.\n",
    "\n",
    "**Level 4 - Integrity**\n",
    "Hash scripts at install time, verify hash before execution to detect tampering.\n",
    "\n",
    "We could implement these incrementally and let users/skills choose their trust level. Perhaps a `Skill.verify()` method that returns a report?\n",
    "\n",
    "Should we start simple - maybe just `run_script()` with basic execution first, then layer on safety checks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bea8175",
   "metadata": {},
   "source": [
    "So, So I think what we probably want as a baseline is the allowed tools and safe run combination. And then if a tool isn't declared, then we need to run it through the AST for an agent. So when you build an agent, if it decides to use the skills, an agent should be declared with a set of security parameters. And then the tools basically build off of that. Do you think through what that might look like? \n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ \n",
    "\n",
    "Good thinking! Here's how I see this working:\n",
    "\n",
    "**Agent Security Context**\n",
    "```python\n",
    "@dataclass\n",
    "class SecurityPolicy:\n",
    "    allowed_tools: list[str]  # Tools this agent can use\n",
    "    require_declaration: bool = True  # Skills must declare allowed-tools\n",
    "    verify_scripts: bool = True  # Run static analysis before execution\n",
    "```\n",
    "\n",
    "**Execution flow:**\n",
    "1. Agent activates a skill\n",
    "2. Check: skill's `allowed-tools` âŠ† agent's `allowed_tools`?\n",
    "3. If skill doesn't declare tools and `require_declaration=True` â†’ AST analysis required\n",
    "4. At runtime, `safe_run` enforces the allowlist\n",
    "\n",
    "**Skill.run_script() logic:**\n",
    "```python\n",
    "def run_script(self, name, *args, policy=None):\n",
    "    # 1. If policy provided, validate skill's allowed-tools against it\n",
    "    # 2. If skill has no allowed-tools and policy requires declaration â†’ analyze with AST\n",
    "    # 3. Build safe_run allowlist from intersection of skill + policy\n",
    "    # 4. Execute with safe_run\n",
    "```\n",
    "\n",
    "This is similar to mobile app permissions - skill declares what it needs, agent approves at activation, runtime enforces.\n",
    "\n",
    "Should we:\n",
    "1. Create a `SecurityPolicy` dataclass first?\n",
    "2. Or start with a simpler `run_script()` that takes an optional allowlist parameter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class SecurityPolicy:\n",
    "    allowed_tools: list[str]  # External bash commands\n",
    "    allowed_capabilities: set[str] = None  # Python capabilities like 'filesystem', 'network'\n",
    "    require_declaration: bool = True  # Skills must declare allowed-tools\n",
    "    verify_scripts: bool = True  # Run static analysis before execution\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.allowed_capabilities is None:\n",
    "            self.allowed_capabilities = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb32d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _build_allowlist(skill_tools:str, policy:SecurityPolicy=None):\n",
    "    \"Build allowlist from skill's allowed-tools and optional policy\"\n",
    "    if not skill_tools and not policy: return None\n",
    "    \n",
    "    skill_list = [t.strip() for t in skill_tools.split(',')] if skill_tools else []\n",
    "    if not policy: return skill_list\n",
    "    \n",
    "    # Intersect skill tools with policy's allowed tools\n",
    "    return [t for t in skill_list if t in policy.allowed_tools] if skill_list else policy.allowed_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c5f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def run_script(self:Skill, name:str, *args, policy:SecurityPolicy=None):\n",
    "    \"Execute a script from the scripts/ directory with optional security policy\"\n",
    "    script_path = self.path/'scripts'/name\n",
    "    if not script_path.exists(): \n",
    "        raise FileNotFoundError(f\"Script '{name}' not found in {self.path}/scripts\")\n",
    "    \n",
    "    # Validate policy requirements\n",
    "    if policy:\n",
    "        if policy.require_declaration and not self.allowed_tools:\n",
    "            raise ValueError(f\"Skill '{self.name}' must declare allowed-tools\")\n",
    "        \n",
    "        # Validate Python script capabilities\n",
    "        if script_path.suffix == '.py' and policy.verify_scripts:\n",
    "            required = get_capabilities(script_path)\n",
    "            if not required <= policy.allowed_capabilities:\n",
    "                disallowed = required - policy.allowed_capabilities\n",
    "                raise ValueError(f\"Script requires disallowed capabilities: {disallowed}\")\n",
    "    \n",
    "    # Build allowlist and execute\n",
    "    allowlist = _build_allowlist(self.allowed_tools, policy)\n",
    "    argstr = ' '.join(str(a) for a in args)\n",
    "    \n",
    "    if script_path.suffix == '.py':\n",
    "        return run_cmd('python', f\"{script_path} {argstr}\")\n",
    "    \n",
    "    # Bash script with safe_run if allowlist exists\n",
    "    if allowlist:\n",
    "        cmd = f\"{script_path} {argstr}\" if args else str(script_path)\n",
    "        return safe_run(cmd, allowed=allowlist)\n",
    "    \n",
    "    return run_cmd('bash', f\"{script_path} {argstr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeed486",
   "metadata": {},
   "source": [
    "## Agentic Security Model\n",
    "\n",
    "### Core Concept\n",
    "Skills provide **tools** (not just scripts) to general-purpose agents. Security should be capability-based, not call-based.\n",
    "\n",
    "### Agent Architecture\n",
    "```\n",
    "Agent (claudette/lisette)\n",
    "â”œâ”€â”€ SecurityPolicy (defines allowed capabilities)\n",
    "â”œâ”€â”€ Built-in tools (bash via safe_run, file ops, etc.)\n",
    "â””â”€â”€ Tool loop (model decides which tool to call)\n",
    "```\n",
    "**General Purpose Agent Flow**\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Agent (claudette/lisette)                                      â”‚\n",
    "â”‚  - SecurityPolicy: defines allowed capabilities                 â”‚\n",
    "â”‚  - Built-in tools: bash (via safe_run), file ops, etc.         â”‚\n",
    "â”‚  - Tool loop: model decides which tool to call                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                              â”‚\n",
    "                              â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Skill Activation                                               â”‚\n",
    "â”‚  1. Load procedural knowledge (instructions â†’ system prompt)    â”‚\n",
    "â”‚  2. Register skill's tools with agent                           â”‚\n",
    "â”‚  3. Validate tool capabilities âŠ† policy capabilities            â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                              â”‚\n",
    "                              â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Tool Loop                                                      â”‚\n",
    "â”‚  - Model chooses to call skill's tool                           â”‚\n",
    "â”‚  - Tool executes (Python function OR bash script)               â”‚\n",
    "â”‚  - Result returns to model                                      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Key Insight:**\n",
    "\n",
    "Python scripts in skills aren't just \"scripts\" - they're **tools** the agent can call. So the question isn't \"what does this script call internally?\" but rather:\n",
    "\n",
    "1. **What capabilities does this tool need?** (file system, network, subprocess, etc.)\n",
    "2. **Does the agent's policy allow those capabilities?**\n",
    "3. **When tool runs, does it stay within those bounds?**\n",
    "\n",
    "**Capability-Based Model:**\n",
    "\n",
    "```python\n",
    "CAPABILITIES = {\n",
    "    'filesystem': ['open', 'os.path', 'pathlib'],\n",
    "    'subprocess': ['subprocess', 'os.system', 'os.popen'],\n",
    "    'network': ['requests', 'urllib', 'socket', 'httpx'],\n",
    "    'eval': ['eval', 'exec', '__import__', 'compile'],\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class SecurityPolicy:\n",
    "    allowed_capabilities: set[str]  # {'filesystem', 'network'}\n",
    "    allowed_tools: list[str]        # External bash commands\n",
    "```\n",
    "\n",
    "Then a skill's Python script is validated by:\n",
    "1. Extract imports\n",
    "2. Map imports â†’ capabilities\n",
    "3. Check capabilities âŠ† policy's allowed_capabilities\n",
    "### Capability-Based Security\n",
    "\n",
    "Instead of checking every function call, we validate based on **capabilities**:\n",
    "\n",
    "```python\n",
    "CAPABILITIES = {\n",
    "    'filesystem': ['open', 'os.path', 'pathlib'],\n",
    "    'subprocess': ['subprocess', 'os.system', 'os.popen'],\n",
    "    'network': ['requests', 'urllib', 'socket', 'httpx'],\n",
    "    'eval': ['eval', 'exec', '__import__', 'compile'],\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class SecurityPolicy:\n",
    "    allowed_capabilities: set[str]  # e.g., {'filesystem', 'network'}\n",
    "    allowed_tools: list[str]        # External bash commands\n",
    "```\n",
    "\n",
    "### Validation Flow\n",
    "\n",
    "When a skill is activated:\n",
    "1. Extract imports from Python scripts\n",
    "2. Map imports â†’ required capabilities\n",
    "3. Validate: skill's capabilities âŠ† agent's allowed_capabilities\n",
    "4. Register skill's tools with agent\n",
    "5. At runtime, tool executes within capability bounds\n",
    "\n",
    "### Key Distinction\n",
    "\n",
    "- **Not a threat**: String methods (`str.split()`), local functions, pure Python\n",
    "- **Actual threat**: Importing/using capabilities not in policy (subprocess, network, eval)\n",
    "\n",
    "### Design Goal\n",
    "\n",
    "Enable agents to extend capabilities via skills while maintaining security through:\n",
    "- Explicit capability declaration\n",
    "- Static analysis of imports\n",
    "- Runtime enforcement via safe_run (bash) and capability checking (Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c55666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "CAPABILITIES = {\n",
    "    'filesystem': {'open', 'pathlib.Path', 'os.path', 'os.remove', 'os.rename', 'shutil'},\n",
    "    'subprocess': {'subprocess', 'os.system', 'os.popen', 'os.spawn'},\n",
    "    'network': {'requests', 'urllib', 'socket', 'httpx', 'http.client'},\n",
    "    'eval': {'eval', 'exec', '__import__', 'compile'},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50233cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _extract_imports(tree):\n",
    "    \"Extract all imported modules from AST\"\n",
    "    imports = set()\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Import):\n",
    "            for alias in node.names:\n",
    "                imports.add(alias.name.split('.')[0])  # Get root module\n",
    "        elif isinstance(node, ast.ImportFrom):\n",
    "            if node.module:\n",
    "                imports.add(node.module.split('.')[0])\n",
    "    return imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d2cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_capabilities(script_path:Path):\n",
    "    \"Extract required capabilities from Python script based on imports\"\n",
    "    content = script_path.read_text()\n",
    "    try: tree = ast.parse(content)\n",
    "    except SyntaxError as e: raise ValueError(f\"Invalid Python syntax in {script_path}: {e}\")\n",
    "    \n",
    "    imports = _extract_imports(tree)\n",
    "    required = set()\n",
    "    \n",
    "    for cap, modules in CAPABILITIES.items():\n",
    "        if imports & modules:  # Intersection\n",
    "            required.add(cap)\n",
    "    \n",
    "    return required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a44963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def validate_capabilities(skill:Skill, policy:SecurityPolicy):\n",
    "    \"Check if skill's Python scripts stay within policy's allowed capabilities\"\n",
    "    scripts_dir = skill.path/'scripts'\n",
    "    if not scripts_dir.exists(): return True\n",
    "    \n",
    "    for script in scripts_dir.glob('*.py'):\n",
    "        required = get_capabilities(script)\n",
    "        if not required <= policy.allowed_capabilities:\n",
    "            disallowed = required - policy.allowed_capabilities\n",
    "            raise ValueError(f\"Script {script.name} requires capabilities not in policy: {disallowed}\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658f41a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with policy that allows filesystem capability\n",
    "policy = SecurityPolicy(\n",
    "    allowed_tools=['python', 'grep', 'cat'],\n",
    "    allowed_capabilities={'filesystem'}\n",
    ")\n",
    "\n",
    "# This should work - analyze.py only uses sys (no dangerous capabilities)\n",
    "result = skill2.run_script('analyze.py', policy=policy)\n",
    "print(result)\n",
    "\n",
    "# Test capability extraction\n",
    "caps = get_capabilities(Path('../skills/code-reviewer/scripts/analyze.py'))\n",
    "print(f\"Required capabilities: {caps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec587a5",
   "metadata": {},
   "source": [
    "Ok. Did this work?\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes! It worked perfectly. The test shows:\n",
    "\n",
    "1. âœ… Script executed successfully: `{'lines': 1, 'non_empty': 0, 'comments': 0}`\n",
    "2. âœ… Capability extraction worked: `Required capabilities: set()` - the analyze.py script only imports `sys` and `json`, which aren't flagged as dangerous capabilities\n",
    "\n",
    "This means our capability-based validation is working correctly. The script doesn't require any special capabilities (filesystem, subprocess, network, or eval), so it passes validation.\n",
    "\n",
    "Now we need to finish the remaining core functions. What's next:\n",
    "\n",
    "1. **`to_prompt()`** - Serialize skill for prompt injection\n",
    "2. **Test with a script that DOES have capabilities** - to verify validation catches violations\n",
    "\n",
    "Which would you like to do next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca713f6a",
   "metadata": {},
   "source": [
    "We should probably test a script that DOES have capabilities\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good idea! Let's create a test script with actual capabilities. We could add a script to one of our skills that uses `requests` (network capability):\n",
    "\n",
    "```python\n",
    "# Create a test script with network capability\n",
    "test_script = \"\"\"import requests\n",
    "import json\n",
    "\n",
    "def fetch_data(url):\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(fetch_data('https://api.example.com/data'))\n",
    "\"\"\"\n",
    "\n",
    "# Write it to code-reviewer/scripts/\n",
    "Path('../skills/code-reviewer/scripts/fetch_data.py').write_text(test_script)\n",
    "\n",
    "# Test capability extraction\n",
    "caps = get_capabilities(Path('../skills/code-reviewer/scripts/fetch_data.py'))\n",
    "print(f\"Required capabilities: {caps}\")\n",
    "\n",
    "# Test with policy that DOESN'T allow network\n",
    "policy_no_network = SecurityPolicy(\n",
    "    allowed_tools=['python'],\n",
    "    allowed_capabilities={'filesystem'}\n",
    ")\n",
    "\n",
    "# This should FAIL\n",
    "try:\n",
    "    result = skill2.run_script('fetch_data.py', policy=policy_no_network)\n",
    "    print(\"ERROR: Should have raised ValueError!\")\n",
    "except ValueError as e:\n",
    "    print(f\"âœ“ Correctly blocked: {e}\")\n",
    "```\n",
    "\n",
    "Should I add this test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0e1ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test script with network capability\n",
    "test_script = \"\"\"import requests\n",
    "import json\n",
    "\n",
    "def fetch_data(url):\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(fetch_data('https://api.example.com/data'))\n",
    "\"\"\"\n",
    "\n",
    "# Write it to code-reviewer/scripts/\n",
    "Path('../skills/code-reviewer/scripts/fetch_data.py').write_text(test_script)\n",
    "\n",
    "# Test capability extraction\n",
    "caps = get_capabilities(Path('../skills/code-reviewer/scripts/fetch_data.py'))\n",
    "print(f\"Required capabilities: {caps}\")\n",
    "\n",
    "# Test with policy that DOESN'T allow network\n",
    "policy_no_network = SecurityPolicy(\n",
    "    allowed_tools=['python'],\n",
    "    allowed_capabilities={'filesystem'}\n",
    ")\n",
    "\n",
    "# This should FAIL\n",
    "try:\n",
    "    result = skill2.run_script('fetch_data.py', policy=policy_no_network)\n",
    "    print(\"ERROR: Should have raised ValueError!\")\n",
    "except ValueError as e:\n",
    "    print(f\"âœ“ Correctly blocked: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90fd749",
   "metadata": {},
   "source": [
    "Ok. What's next?\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! The capability validation is working correctly - it detected the `network` capability and blocked execution.\n",
    "\n",
    "Now let's finish the remaining core functions:\n",
    "\n",
    "1. **`to_prompt()`** - Format skill for injection into agent's system prompt\n",
    "2. **Entry point discovery** - Load skills from pip-installed packages\n",
    "3. **Environment variable paths** - Support `SOLVEIT_SKILLS_PATH`\n",
    "\n",
    "Let's start with `to_prompt()` since it's essential for both solveit and SkilledAgent:\n",
    "\n",
    "```python\n",
    "@patch\n",
    "def to_prompt(self:Skill):\n",
    "    \"Format skill instructions for injection into system prompt\"\n",
    "    prompt = f\"# {self.name}\\n\\n{self.description}\\n\\n{self.instructions}\"\n",
    "    \n",
    "    if self.compatibility:\n",
    "        prompt += f\"\\n\\n**Compatibility**: {self.compatibility}\"\n",
    "    \n",
    "    if self.allowed_tools:\n",
    "        prompt += f\"\\n\\n**Required tools**: {self.allowed_tools}\"\n",
    "    \n",
    "    return prompt\n",
    "```\n",
    "\n",
    "Should I add this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2a7d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def to_prompt(self:Skill):\n",
    "    \"Format skill instructions for injection into system prompt\"\n",
    "    prompt = f\"# {self.name}\\n\\n{self.description}\\n\\n{self.instructions}\"\n",
    "    \n",
    "    if self.compatibility:\n",
    "        prompt += f\"\\n\\n**Compatibility**: {self.compatibility}\"\n",
    "    \n",
    "    if self.allowed_tools:\n",
    "        prompt += f\"\\n\\n**Required tools**: {self.allowed_tools}\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9753b509",
   "metadata": {},
   "source": [
    "Ok. How do we test this?\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let's test it with our hello-world skill:\n",
    "\n",
    "```python\n",
    "prompt_text = skill.to_prompt()\n",
    "print(prompt_text)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "# Test with code-reviewer (has more metadata)\n",
    "prompt_text2 = skill2.to_prompt()\n",
    "print(prompt_text2[:200])  # First 200 chars\n",
    "\n",
    "# Assertions\n",
    "assert skill.name in prompt_text\n",
    "assert skill.description in prompt_text\n",
    "assert skill.instructions in prompt_text\n",
    "```\n",
    "\n",
    "Should I add this test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701bf0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = skill.to_prompt()\n",
    "print(prompt_text)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "# Test with code-reviewer (has more metadata)\n",
    "prompt_text2 = skill2.to_prompt()\n",
    "print(prompt_text2[:200])  # First 200 chars\n",
    "\n",
    "# Assertions\n",
    "assert skill.name in prompt_text\n",
    "assert skill.description in prompt_text\n",
    "assert skill.instructions in prompt_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4815f48c",
   "metadata": {},
   "source": [
    "Ok. Did this work?\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes! It worked perfectly. The `to_prompt()` method successfully formatted both skills:\n",
    "\n",
    "1. âœ… hello-world skill includes name, description, and instructions\n",
    "2. âœ… code-reviewer skill formatted correctly (we can see the beginning)\n",
    "3. âœ… All assertions passed\n",
    "\n",
    "Now we have the core skill functionality complete. What's next:\n",
    "\n",
    "1. **Entry point discovery** - Load skills from pip-installed packages\n",
    "2. **Environment variable paths** - Support `SOLVEIT_SKILLS_PATH`\n",
    "3. **Multi-source discovery** - Combine filesystem + entry points + env vars\n",
    "\n",
    "Which would you like to tackle next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884fc035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def discover_from_paths(paths):\n",
    "    \"Discover skills from a list of filesystem paths\"\n",
    "    skills = []\n",
    "    for path in paths:\n",
    "        path = Path(path)\n",
    "        if path.exists():\n",
    "            skills.extend(discover_skills(path))\n",
    "    return skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15adf429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def discover_from_entrypoints():\n",
    "    \"Discover skills from pip-installed packages via entry points\"\n",
    "    try:\n",
    "        from importlib.metadata import entry_points\n",
    "    except ImportError:\n",
    "        from importlib_metadata import entry_points  # Python < 3.8\n",
    "    \n",
    "    skills = []\n",
    "    eps = entry_points()\n",
    "    \n",
    "    # Handle both dict and SelectableGroups return types\n",
    "    group = eps.get('skillhelper.skills', []) if hasattr(eps, 'get') else eps.select(group='skillhelper.skills')\n",
    "    \n",
    "    for ep in group:\n",
    "        try:\n",
    "            get_skill_path = ep.load()\n",
    "            skill_path = get_skill_path()\n",
    "            skills.append(load_skill(skill_path))\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed to load skill from entry point {ep.name}: {e}\")\n",
    "    \n",
    "    return skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a74b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def discover_all():\n",
    "    \"Discover skills from all sources: filesystem, entry points, and environment\"\n",
    "    skills = []\n",
    "    \n",
    "    # 1. Entry points (pip-installed packages)\n",
    "    skills.extend(discover_from_entrypoints())\n",
    "    \n",
    "    # 2. Standard filesystem locations\n",
    "    standard_paths = [\n",
    "        Path.home() / '.skills',  # User skills\n",
    "        Path('./skills'),          # Project-local skills\n",
    "        Path('../skills'),         # nbdev development pattern\n",
    "    ]\n",
    "    skills.extend(discover_from_paths(standard_paths))\n",
    "    \n",
    "    # 3. Environment variable paths\n",
    "    env_path = os.getenv('SOLVEIT_SKILLS_PATH')\n",
    "    if env_path:\n",
    "        env_paths = env_path.split(':')\n",
    "        skills.extend(discover_from_paths(env_paths))\n",
    "    \n",
    "    # Deduplicate by name (first found wins)\n",
    "    seen = set()\n",
    "    unique = []\n",
    "    for skill in skills:\n",
    "        if skill.name not in seen:\n",
    "            seen.add(skill.name)\n",
    "            unique.append(skill)\n",
    "    \n",
    "    return unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1ff25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test discover_all with updated paths\n",
    "all_skills = discover_all()\n",
    "print(f\"Found {len(all_skills)} skills total:\")\n",
    "for s in all_skills:\n",
    "    print(f\"  - {s.name}: {s.description[:50]}...\")\n",
    "\n",
    "assert len(all_skills) >= 2\n",
    "assert any(s.name == 'hello-world' for s in all_skills)\n",
    "assert any(s.name == 'code-reviewer' for s in all_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ef05d0",
   "metadata": {},
   "source": [
    "Ok. Is there anything we haven't done for the skillshelper core?\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ \n",
    "\n",
    "Let me review what we have in core vs what's still needed:\n",
    "\n",
    "**Done in core:**\n",
    "- `parse_frontmatter()` âœ“\n",
    "- `Skill` dataclass âœ“\n",
    "- `load_skill()` âœ“\n",
    "- `discover_skills()` / `discover_from_paths()` / `discover_from_entrypoints()` / `discover_all()` âœ“\n",
    "- `load_reference()` âœ“\n",
    "- `asset_path()` âœ“\n",
    "- `run_script()` âœ“\n",
    "- `SecurityPolicy` dataclass âœ“\n",
    "- `CAPABILITIES` dict âœ“\n",
    "- `get_capabilities()` / `validate_capabilities()` âœ“\n",
    "- `to_prompt()` âœ“\n",
    "\n",
    "**Potentially missing from core:**\n",
    "1. **`list_skills()`** - Convenience function to show available skills (for solveit tool use)\n",
    "2. **`skill_tool_info()`** - Returns XML summary for prompt injection\n",
    "3. **Export directives** - Make sure all functions have `#| export` for nbdev\n",
    "\n",
    "**Belongs in SkilledAgent notebook:**\n",
    "- `activate_skill()` - Requires agent context\n",
    "- `teach()` - Requires agent context\n",
    "- Tool registration with claudette/lisette\n",
    "\n",
    "Should we add `list_skills()` and `skill_tool_info()` to core, then clean up the exports?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bb7045",
   "metadata": {},
   "source": [
    "OK. Could we implement the tools list_skills() and skill_tool_info()?\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! Let's implement these helper functions:\n",
    "\n",
    "```python\n",
    "def list_skills(skills=None):\n",
    "    \"List available skills with name and description\"\n",
    "    if skills is None: skills = discover_all()\n",
    "    \n",
    "    result = []\n",
    "    for skill in skills:\n",
    "        result.append(f\"**{skill.name}**: {skill.description}\")\n",
    "    \n",
    "    return '\\n'.join(result)\n",
    "```\n",
    "\n",
    "```python\n",
    "def skill_tool_info(skills=None):\n",
    "    \"Generate XML summary of available skills for prompt injection\"\n",
    "    if skills is None: skills = discover_all()\n",
    "    \n",
    "    xml = [\"<available_skills>\"]\n",
    "    for skill in skills:\n",
    "        xml.append(f\"  <skill name='{skill.name}'>\")\n",
    "        xml.append(f\"    <description>{skill.description}</description>\")\n",
    "        if skill.allowed_tools:\n",
    "            xml.append(f\"    <requires_tools>{skill.allowed_tools}</requires_tools>\")\n",
    "        xml.append(f\"  </skill>\")\n",
    "    xml.append(\"</available_skills>\")\n",
    "    \n",
    "    return '\\n'.join(xml)\n",
    "```\n",
    "\n",
    "Should I add these?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e63c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def list_skills(skills=None):\n",
    "    \"List available skills with name and description\"\n",
    "    if skills is None: skills = discover_all()\n",
    "    \n",
    "    result = []\n",
    "    for skill in skills:\n",
    "        result.append(f\"**{skill.name}**: {skill.description}\")\n",
    "    \n",
    "    return '\\n'.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0a9d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def skill_tool_info(skills=None):\n",
    "    \"List available skills for prompt injection\"\n",
    "    if skills is None: skills = discover_all()\n",
    "    \n",
    "    lines = [\"**Available Skills:**\"]\n",
    "    for skill in skills:\n",
    "        lines.append(f\"- &`{skill.name}`: {skill.description}\")\n",
    "    \n",
    "    return '\\n'.join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bbf7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_tool_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ab1f4",
   "metadata": {},
   "source": [
    "So. Not all skills are tools?\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ \n",
    "\n",
    "Good point! You're right. Looking at our design:\n",
    "\n",
    "- **Skills with only SKILL.md** = Pure procedural knowledge, no callable tool (like hello-world)\n",
    "- **Skills with scripts/** = Provide callable functionality (tool-like)\n",
    "\n",
    "So `skill_tool_info()` is misleading. It should probably be just `skill_info()`, and the `&` backtick syntax only applies if the skill actually provides callable tools.\n",
    "\n",
    "Should we:\n",
    "1. Rename to `skill_info()` \n",
    "2. Add a `has_tools` property to `Skill` that checks if `scripts/` exists\n",
    "3. Only show the `&` syntax for skills that actually have callable scripts\n",
    "\n",
    "What do you think?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d815b7a",
   "metadata": {},
   "source": [
    "There is a difference between a tool and a script in terms of interface.\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ \n",
    "\n",
    "You're right. Key distinction:\n",
    "\n",
    "- **Script**: Executable file called via `run_script('name.py', *args)`. Returns stdout. Human-oriented or simple input/output.\n",
    "\n",
    "- **Tool**: Python function with type annotations + docstring. Agent can see schema, call it in tool loop, get structured results.\n",
    "\n",
    "So a skill could expose:\n",
    "1. **Knowledge only** - SKILL.md instructions\n",
    "2. **Scripts** - Helper executables (called by agent or human)\n",
    "3. **Tools** - Functions registered with agent for tool loop\n",
    "\n",
    "For a skill to provide tools, it would need actual Python functions, perhaps in an `__init__.py` or a `tools.py`, that get imported and registered with the agent.\n",
    "\n",
    "Does that match your thinking?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd01548",
   "metadata": {},
   "source": [
    "Yes.\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ \n",
    "\n",
    "So for core, we should add a way to discover what tools a skill provides. Perhaps:\n",
    "\n",
    "```python\n",
    "@patch\n",
    "def get_tools(self:Skill):\n",
    "    \"Return callable tools from the skill (functions from tools.py)\"\n",
    "    tools_py = self.path / 'tools.py'\n",
    "    if not tools_py.exists(): return []\n",
    "    \n",
    "    # Import the module and extract functions with annotations\n",
    "    ...\n",
    "```\n",
    "\n",
    "And rename `skill_tool_info()` to just `skill_info()`.\n",
    "\n",
    "The actual registration of tools with claudette/lisette would happen in the SkilledAgent notebook.\n",
    "\n",
    "Should we:\n",
    "1. Add `get_tools()` to Skill now\n",
    "2. Or leave that for SkilledAgent notebook since it requires the agent context?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d6d6c4",
   "metadata": {},
   "source": [
    "So, the I don't know if we need a skill_info() for non tools since run_cmd will handle that case based on the skill.md description.\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ \n",
    "\n",
    "Right! For non-tool skills:\n",
    "- `list_skills()` shows what's available\n",
    "- `to_prompt()` injects instructions when activated\n",
    "\n",
    "That covers the procedural knowledge case. The actual tool registration would be handled in SkilledAgent.\n",
    "\n",
    "So I think core is complete. Should we:\n",
    "1. Clean up the exports and make sure everything has `#| export`\n",
    "2. Move on to creating the SkilledAgent notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607b4ed0",
   "metadata": {},
   "source": [
    "We need to create and test the new get_tools().\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good point! Let's implement `get_tools()`. It should import a skill's `tools.py` and extract callable functions:\n",
    "\n",
    "```python\n",
    "@patch\n",
    "def get_tools(self:Skill):\n",
    "    \"Return callable tool functions from the skill's tools.py\"\n",
    "    tools_py = self.path / 'tools.py'\n",
    "    if not tools_py.exists(): return {}\n",
    "    \n",
    "    # Dynamically import the tools module\n",
    "    import importlib.util\n",
    "    spec = importlib.util.spec_from_file_location(f\"{self.name}.tools\", tools_py)\n",
    "    if not spec or not spec.loader: return {}\n",
    "    \n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    \n",
    "    # Extract functions with type annotations and docstrings\n",
    "    tools = {}\n",
    "    for name in dir(module):\n",
    "        if name.startswith('_'): continue\n",
    "        obj = getattr(module, name)\n",
    "        if callable(obj) and hasattr(obj, '__annotations__') and obj.__doc__:\n",
    "            tools[name] = obj\n",
    "    \n",
    "    return tools\n",
    "```\n",
    "\n",
    "But we need a test skill with a `tools.py` first. Should I create one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ba773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_tools(self:Skill):\n",
    "    \"Return callable tool functions from the skill's tools.py\"\n",
    "    tools_py = self.path / 'tools.py'\n",
    "    if not tools_py.exists(): return {}\n",
    "    \n",
    "    # Dynamically import the tools module\n",
    "    import importlib.util\n",
    "    spec = importlib.util.spec_from_file_location(f\"{self.name}.tools\", tools_py)\n",
    "    if not spec or not spec.loader: return {}\n",
    "    \n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    \n",
    "    # Extract functions with type annotations and docstrings\n",
    "    tools = {}\n",
    "    for name in dir(module):\n",
    "        if name.startswith('_'): continue\n",
    "        obj = getattr(module, name)\n",
    "        if callable(obj) and hasattr(obj, '__annotations__') and obj.__doc__:\n",
    "            tools[name] = obj\n",
    "    \n",
    "    return tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd00561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple tools.py for code-reviewer\n",
    "tools_code = \"\"\"def count_lines(filepath: str) -> dict:\n",
    "    '''Count lines in a file'''\n",
    "    with open(filepath) as f:\n",
    "        lines = f.readlines()\n",
    "    return {\n",
    "        'total': len(lines),\n",
    "        'non_empty': len([l for l in lines if l.strip()])\n",
    "    }\n",
    "\n",
    "def check_style(code: str) -> str:\n",
    "    '''Check if code follows basic style rules'''\n",
    "    issues = []\n",
    "    if '  ' in code and '    ' not in code:\n",
    "        issues.append('Uses 2-space indentation instead of 4')\n",
    "    if len(code.split('\\\\n')) > 100:\n",
    "        issues.append('File is longer than 100 lines')\n",
    "    return '\\\\n'.join(issues) if issues else 'No style issues found'\n",
    "\"\"\"\n",
    "\n",
    "Path('../skills/code-reviewer/tools.py').write_text(tools_code)\n",
    "\n",
    "# Test get_tools\n",
    "tools = skill2.get_tools()\n",
    "print(f\"Found {len(tools)} tools:\")\n",
    "for name, func in tools.items():\n",
    "    print(f\"  - {name}: {func.__doc__}\")\n",
    "\n",
    "assert 'count_lines' in tools\n",
    "assert 'check_style' in tools"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
